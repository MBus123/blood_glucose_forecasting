{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from models.nbeats import NBeats, Block\n",
    "from data import OhioData\n",
    "from models.lstm_seq import LSTMPredictor\n",
    "from models.nbeats import NBeats\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 24\n",
    "n_features = 11\n",
    "n_layers = 1\n",
    "output_dim = 12\n",
    "amount_fc = 3\n",
    "hidden_dim = 10\n",
    "\n",
    "n_blocks = 12\n",
    "hidden_dim2 = 64\n",
    "early_stopping_counter = 10\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTMPredictor(input_size=n_features, hidden_size=hidden_dim, num_layers=n_layers, bidirectional=False).to(device)\n",
    "lstm_model.load_state_dict(torch.load(f\"checkpoints/lstm_best_{output_dim}.chkpt\"))\n",
    "lstm_model = lstm_model.eval()\n",
    "\n",
    "nbeats_model = NBeats(n_blocks=n_blocks, input_dim=input_dim, parameter_dim=n_features, output_dim=output_dim, amount_fc=amount_fc, hidden_dim=hidden_dim2).to(device)\n",
    "nbeats_model.load_state_dict(torch.load(f\"checkpoints/nbeats_best_{output_dim}.chkpt\"))\n",
    "nbeats_model = nbeats_model.eval()\n",
    "\n",
    "# train data is only required for scale_max[\"cbg\"] value\n",
    "train_data = OhioData()\n",
    "data = OhioData(mode=\"validation\", h=output_dim)\n",
    "val_loader = DataLoader(data, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_nbeats(batch):\n",
    "    batch = batch.reshape(-1, input_dim, n_features)\n",
    "    batch_tmp = batch[:, :, 0].clone().detach()\n",
    "    batch[:, :, 0] = batch[:, :, 2]\n",
    "    batch[:, :, 2] = batch_tmp\n",
    "    return batch.permute(0, 2, 1).reshape(-1, input_dim * n_features)\n",
    "\n",
    "def prepare_data_lstm(batch):\n",
    "    batch = batch.reshape(batch.shape[0], input_dim, n_features).permute(1, 0, 2)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 3275/23911 [00:12<01:15, 274.37it/s]"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y, _ in tqdm(val_loader):\n",
    "        x_lstm = prepare_data_lstm(x).cuda()\n",
    "        x_nbeats = prepare_data_nbeats(x).cuda()\n",
    "        y_lstm = lstm_model(x_lstm, x_lstm[-1].unsqueeze(0)[:, :, 2].unsqueeze(2), teacher_force=False)\n",
    "        y_nbeats = nbeats_model(x_nbeats)\n",
    "        y_lstm = y_lstm.squeeze().cpu().numpy()\n",
    "        y_nbeats = y_nbeats.squeeze().cpu().numpy()\n",
    "        y_pred = np.concatenate((y_lstm, y_nbeats), axis=0) * train_data.scale_max[\"cbg\"]\n",
    "        y *= train_data.scale_max[\"cbg\"]\n",
    "        X.append(y_pred)\n",
    "        Y.append(y.squeeze().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9252092329733997"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X, Y)\n",
    "reg.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = OhioData(mode=\"test\")\n",
    "test_loader = DataLoader(test_data, batch_size=1, num_workers=0)\n",
    "\n",
    "mse_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 14.35, Running Loss: 3.27: 100%|██████████| 28426/28426 [02:56<00:00, 160.76it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rMSE: 14.345913227285662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_loader) as t:\n",
    "        for x, y, mask in t:\n",
    "            x_lstm = prepare_data_lstm(x).cuda()\n",
    "            x_nbeats = prepare_data_nbeats(x).cuda()\n",
    "            y_lstm = lstm_model(x_lstm, x_lstm[-1].unsqueeze(0)[:, :, 2].unsqueeze(2), teacher_force=False)\n",
    "            y_nbeats = nbeats_model(x_nbeats)\n",
    "            y_lstm = y_lstm.squeeze().cpu().numpy()\n",
    "            y_nbeats = y_nbeats.squeeze().cpu().numpy()\n",
    "            y_pred = np.concatenate((y_lstm, y_nbeats), axis=0) * train_data.scale_max[\"cbg\"]\n",
    "            y_pred = [y_pred]\n",
    "            y_pred = torch.tensor(reg.predict(y_pred))\n",
    "            # scale back to original range, because otherwise the results cannot bne compared to others\n",
    "            y = y * train_data.scale_max[\"cbg\"]\n",
    "            loss = mse_loss(y_pred, y)\n",
    "            total_loss += loss.item()\n",
    "            t.set_description(f\"Test Loss: {np.sqrt(total_loss / len(test_loader)):.2f}, Running Loss: {np.sqrt(loss.item()):.2f}\")\n",
    "\n",
    "print(f\"Final rMSE: {np.sqrt(total_loss / len(test_loader))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate results per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = [559, 563, 570, 575, 588, 591, 540, 544, 552, 567, 584, 596]\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "mae_loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patient: 559, rMSE: 14.23, MAE: 9.22: 100%|██████████| 2142/2142 [00:13<00:00, 160.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Patient: 559, rMSE: 14.23, MAE: 9.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patient: 563, rMSE: 13.91, MAE: 9.00: 100%|██████████| 2446/2446 [00:15<00:00, 161.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Patient: 563, rMSE: 13.91, MAE: 9.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patient: 570, rMSE: 12.27, MAE: 8.27: 100%|██████████| 2435/2435 [00:15<00:00, 161.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Patient: 570, rMSE: 12.27, MAE: 8.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patient: 575, rMSE: 16.19, MAE: 9.88: 100%|██████████| 2249/2249 [00:13<00:00, 161.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Patient: 575, rMSE: 16.19, MAE: 9.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patient: 588, rMSE: 13.79, MAE: 9.15: 100%|██████████| 2698/2698 [00:16<00:00, 164.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Patient: 588, rMSE: 13.79, MAE: 9.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patient: 591, rMSE: 15.49, MAE: 10.22: 100%|██████████| 2605/2605 [00:16<00:00, 162.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Patient: 591, rMSE: 15.49, MAE: 10.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patient: 540, rMSE: 16.13, MAE: 10.83: 100%|██████████| 2617/2617 [00:16<00:00, 161.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Patient: 540, rMSE: 16.13, MAE: 10.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patient: 544, rMSE: 13.16, MAE: 8.90: 100%|██████████| 2499/2499 [00:15<00:00, 161.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Patient: 544, rMSE: 13.16, MAE: 8.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patient: 552, rMSE: 12.16, MAE: 8.40: 100%|██████████| 2023/2023 [00:12<00:00, 163.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Patient: 552, rMSE: 12.16, MAE: 8.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patient: 567, rMSE: 15.66, MAE: 10.30: 100%|██████████| 2017/2017 [00:12<00:00, 161.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Patient: 567, rMSE: 15.66, MAE: 10.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patient: 584, rMSE: 15.52, MAE: 10.33: 100%|██████████| 2169/2169 [00:13<00:00, 162.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Patient: 584, rMSE: 15.52, MAE: 10.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patient: 596, rMSE: 12.84, MAE: 8.45: 100%|██████████| 2526/2526 [00:15<00:00, 160.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Patient: 596, rMSE: 12.84, MAE: 8.45\n",
      "Mean results - MAE: 9.412001328873915, rMSE: 14.350235417323082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "maes = []\n",
    "mses = []\n",
    "with torch.no_grad():\n",
    "    for id in patient_ids:\n",
    "        total_mae = 0\n",
    "        total_mse = 0\n",
    "        test_data = OhioData(mode=\"test\", patient_id=id)\n",
    "        test_loader = DataLoader(test_data, batch_size=1, num_workers=0)\n",
    "        with tqdm(test_loader) as t:\n",
    "            for x, y, mask in t:\n",
    "                x_lstm = prepare_data_lstm(x).cuda()\n",
    "                x_nbeats = prepare_data_nbeats(x).cuda()\n",
    "                y_lstm = lstm_model(x_lstm, x_lstm[-1].unsqueeze(0)[:, :, 2].unsqueeze(2), teacher_force=False)\n",
    "                y_nbeats = nbeats_model(x_nbeats)\n",
    "                y_lstm = y_lstm.squeeze().cpu().numpy()\n",
    "                y_nbeats = y_nbeats.squeeze().cpu().numpy()\n",
    "                y_pred = np.concatenate((y_lstm, y_nbeats), axis=0) * train_data.scale_max[\"cbg\"]\n",
    "                y_pred = [y_pred]\n",
    "                y_pred = torch.tensor(reg.predict(y_pred))\n",
    "                # scale back to original range, because otherwise the results cannot bne compared to others\n",
    "                y = y * train_data.scale_max[\"cbg\"]\n",
    "                mse = mse_loss(y_pred, y)\n",
    "                mae = mae_loss(y_pred, y) \n",
    "                total_mae += mae.item()\n",
    "                total_mse += mse.item()\n",
    "                t.set_description(f\"Patient: {id}, rMSE: {np.sqrt(total_mse / len(test_loader)):.2f}, MAE: {total_mae / len(test_loader):.2f}\")\n",
    "        print(f\"Results - Patient: {id}, rMSE: {np.sqrt(total_mse / len(test_loader)):.2f}, MAE: {total_mae / len(test_loader):.2f}\")\n",
    "        maes.append(total_mae / len(test_loader))\n",
    "        mses.append(total_mse / len(test_loader))\n",
    "print(f\"Mean results - MAE: {sum(maes) / len(maes)}, rMSE: {np.sqrt(sum(mses) / len(mses))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
